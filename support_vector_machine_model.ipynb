{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Support Vector Machine Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Extract emotion features using VADER sentiment analysis\u001b[39;00m\n\u001b[0;32m     17\u001b[0m sia \u001b[39m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[1;32m---> 18\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msentiment_scores\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: sia\u001b[39m.\u001b[39;49mpolarity_scores(\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x)))\n\u001b[0;32m     19\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcompound\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msentiment_scores\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39mcompound\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[39m# Extract statistical features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Extract emotion features using VADER sentiment analysis\u001b[39;00m\n\u001b[0;32m     17\u001b[0m sia \u001b[39m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[1;32m---> 18\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msentiment_scores\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: sia\u001b[39m.\u001b[39;49mpolarity_scores(\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x)))\n\u001b[0;32m     19\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcompound\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msentiment_scores\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39mcompound\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[39m# Extract statistical features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\nltk\\sentiment\\vader.py:366\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39m    matched as if it was a normal word in the sentence.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m sentitext \u001b[39m=\u001b[39m SentiText(\n\u001b[0;32m    367\u001b[0m     text, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mPUNC_LIST, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mREGEX_REMOVE_PUNCTUATION\n\u001b[0;32m    368\u001b[0m )\n\u001b[0;32m    369\u001b[0m sentiments \u001b[39m=\u001b[39m []\n\u001b[0;32m    370\u001b[0m words_and_emoticons \u001b[39m=\u001b[39m sentitext\u001b[39m.\u001b[39mwords_and_emoticons\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\nltk\\sentiment\\vader.py:274\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[1;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST \u001b[39m=\u001b[39m punc_list\n\u001b[0;32m    273\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mREGEX_REMOVE_PUNCTUATION \u001b[39m=\u001b[39m regex_remove_punctuation\n\u001b[1;32m--> 274\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwords_and_emoticons \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_words_and_emoticons()\n\u001b[0;32m    275\u001b[0m \u001b[39m# doesn't separate words from\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m# adjacent punctuation (keeps emoticons & contractions)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_cap_diff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallcap_differential(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwords_and_emoticons)\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\nltk\\sentiment\\vader.py:306\u001b[0m, in \u001b[0;36mSentiText._words_and_emoticons\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[39mRemoves leading and trailing puncutation\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[39mLeaves contractions and most emoticons\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[39m    Does not preserve punc-plus-letter emoticons (e.g. :D)\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m wes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msplit()\n\u001b[1;32m--> 306\u001b[0m words_punc_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_words_plus_punc()\n\u001b[0;32m    307\u001b[0m wes \u001b[39m=\u001b[39m [we \u001b[39mfor\u001b[39;00m we \u001b[39min\u001b[39;00m wes \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(we) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m    308\u001b[0m \u001b[39mfor\u001b[39;00m i, we \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(wes):\n",
      "File \u001b[1;32mc:\\Users\\amins\\Desktop\\Project\\.venv\\Lib\\site-packages\\nltk\\sentiment\\vader.py:279\u001b[0m, in \u001b[0;36mSentiText._words_plus_punc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[39m# doesn't separate words from\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[39m# adjacent punctuation (keeps emoticons & contractions)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_cap_diff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallcap_differential(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwords_and_emoticons)\n\u001b[1;32m--> 279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_words_plus_punc\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    280\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39m    Returns mapping of form:\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39m    {\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m    }\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     no_punc_text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mREGEX_REMOVE_PUNCTUATION\u001b[39m.\u001b[39msub(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read and clean the dataset\n",
    "df = pd.read_excel('C://Users//amins//Desktop//Cleaned Dataset.xlsx')\n",
    "\n",
    "\n",
    "# Extract emotion features using VADER sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment_scores'] = df['Text'].apply(lambda x: sia.polarity_scores(' '.join(x)))\n",
    "df['compound'] = df['sentiment_scores'].apply(lambda x: x['compound'])\n",
    "\n",
    "# Extract statistical features\n",
    "df['text_length'] = df['Text'].apply(len)\n",
    "df['average_word_length'] = df['Text'].apply(lambda x: np.mean([len(word) for word in x]) if x else 0)\n",
    "\n",
    "# Combine emotion and statistical features into a single DataFrame\n",
    "feature_df = df[['compound', 'text_length', 'average_word_length']]\n",
    "\n",
    "# Standardize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(feature_df)\n",
    "\n",
    "# Get the target labels\n",
    "# Assuming your target label is in a column named 'Class'\n",
    "y = df['Class'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM classifier using Scikit-learn\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
